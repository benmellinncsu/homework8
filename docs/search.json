[
  {
    "objectID": "hw8.html",
    "href": "hw8.html",
    "title": "Homework 8",
    "section": "",
    "text": "First, upload the data.\n\nlibrary(tidyr)\nlibrary(readr)\ndf &lt;- read_csv(\"SeoulBikeData (1).csv\", locale=locale(encoding=\"latin1\"))\n\nRows: 8760 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): Date, Seasons, Holiday, Functioning Day\ndbl (10): Rented Bike Count, Hour, Temperature(°C), Humidity(%), Wind speed ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCheck out the data:\n\ndim(df)\n\n[1] 8760   14\n\nstr(df)\n\nspc_tbl_ [8,760 × 14] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Date                     : chr [1:8760] \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" ...\n $ Rented Bike Count        : num [1:8760] 254 204 173 107 78 100 181 460 930 490 ...\n $ Hour                     : num [1:8760] 0 1 2 3 4 5 6 7 8 9 ...\n $ Temperature(°C)          : num [1:8760] -5.2 -5.5 -6 -6.2 -6 -6.4 -6.6 -7.4 -7.6 -6.5 ...\n $ Humidity(%)              : num [1:8760] 37 38 39 40 36 37 35 38 37 27 ...\n $ Wind speed (m/s)         : num [1:8760] 2.2 0.8 1 0.9 2.3 1.5 1.3 0.9 1.1 0.5 ...\n $ Visibility (10m)         : num [1:8760] 2000 2000 2000 2000 2000 ...\n $ Dew point temperature(°C): num [1:8760] -17.6 -17.6 -17.7 -17.6 -18.6 -18.7 -19.5 -19.3 -19.8 -22.4 ...\n $ Solar Radiation (MJ/m2)  : num [1:8760] 0 0 0 0 0 0 0 0 0.01 0.23 ...\n $ Rainfall(mm)             : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ Snowfall (cm)            : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ Seasons                  : chr [1:8760] \"Winter\" \"Winter\" \"Winter\" \"Winter\" ...\n $ Holiday                  : chr [1:8760] \"No Holiday\" \"No Holiday\" \"No Holiday\" \"No Holiday\" ...\n $ Functioning Day          : chr [1:8760] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Date = col_character(),\n  ..   `Rented Bike Count` = col_double(),\n  ..   Hour = col_double(),\n  ..   `Temperature(°C)` = col_double(),\n  ..   `Humidity(%)` = col_double(),\n  ..   `Wind speed (m/s)` = col_double(),\n  ..   `Visibility (10m)` = col_double(),\n  ..   `Dew point temperature(°C)` = col_double(),\n  ..   `Solar Radiation (MJ/m2)` = col_double(),\n  ..   `Rainfall(mm)` = col_double(),\n  ..   `Snowfall (cm)` = col_double(),\n  ..   Seasons = col_character(),\n  ..   Holiday = col_character(),\n  ..   `Functioning Day` = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\n\nI’d like to check for missingness.\n\nsum(is.na(df))\n\n[1] 0\n\n\nNo missing data. That’s good!\n\nsummary(df)\n\n     Date           Rented Bike Count      Hour       Temperature(°C) \n Length:8760        Min.   :   0.0    Min.   : 0.00   Min.   :-17.80  \n Class :character   1st Qu.: 191.0    1st Qu.: 5.75   1st Qu.:  3.50  \n Mode  :character   Median : 504.5    Median :11.50   Median : 13.70  \n                    Mean   : 704.6    Mean   :11.50   Mean   : 12.88  \n                    3rd Qu.:1065.2    3rd Qu.:17.25   3rd Qu.: 22.50  \n                    Max.   :3556.0    Max.   :23.00   Max.   : 39.40  \n  Humidity(%)    Wind speed (m/s) Visibility (10m) Dew point temperature(°C)\n Min.   : 0.00   Min.   :0.000    Min.   :  27     Min.   :-30.600          \n 1st Qu.:42.00   1st Qu.:0.900    1st Qu.: 940     1st Qu.: -4.700          \n Median :57.00   Median :1.500    Median :1698     Median :  5.100          \n Mean   :58.23   Mean   :1.725    Mean   :1437     Mean   :  4.074          \n 3rd Qu.:74.00   3rd Qu.:2.300    3rd Qu.:2000     3rd Qu.: 14.800          \n Max.   :98.00   Max.   :7.400    Max.   :2000     Max.   : 27.200          \n Solar Radiation (MJ/m2)  Rainfall(mm)     Snowfall (cm)       Seasons         \n Min.   :0.0000          Min.   : 0.0000   Min.   :0.00000   Length:8760       \n 1st Qu.:0.0000          1st Qu.: 0.0000   1st Qu.:0.00000   Class :character  \n Median :0.0100          Median : 0.0000   Median :0.00000   Mode  :character  \n Mean   :0.5691          Mean   : 0.1487   Mean   :0.07507                     \n 3rd Qu.:0.9300          3rd Qu.: 0.0000   3rd Qu.:0.00000                     \n Max.   :3.5200          Max.   :35.0000   Max.   :8.80000                     \n   Holiday          Functioning Day   \n Length:8760        Length:8760       \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n                                      \n                                      \n                                      \n\n\nCheck unique values in character columns\n\nlapply(df[sapply(df, is.character)], unique)\n\n$Date\n  [1] \"01/12/2017\" \"02/12/2017\" \"03/12/2017\" \"04/12/2017\" \"05/12/2017\"\n  [6] \"06/12/2017\" \"07/12/2017\" \"08/12/2017\" \"09/12/2017\" \"10/12/2017\"\n [11] \"11/12/2017\" \"12/12/2017\" \"13/12/2017\" \"14/12/2017\" \"15/12/2017\"\n [16] \"16/12/2017\" \"17/12/2017\" \"18/12/2017\" \"19/12/2017\" \"20/12/2017\"\n [21] \"21/12/2017\" \"22/12/2017\" \"23/12/2017\" \"24/12/2017\" \"25/12/2017\"\n [26] \"26/12/2017\" \"27/12/2017\" \"28/12/2017\" \"29/12/2017\" \"30/12/2017\"\n [31] \"31/12/2017\" \"01/01/2018\" \"02/01/2018\" \"03/01/2018\" \"04/01/2018\"\n [36] \"05/01/2018\" \"06/01/2018\" \"07/01/2018\" \"08/01/2018\" \"09/01/2018\"\n [41] \"10/01/2018\" \"11/01/2018\" \"12/01/2018\" \"13/01/2018\" \"14/01/2018\"\n [46] \"15/01/2018\" \"16/01/2018\" \"17/01/2018\" \"18/01/2018\" \"19/01/2018\"\n [51] \"20/01/2018\" \"21/01/2018\" \"22/01/2018\" \"23/01/2018\" \"24/01/2018\"\n [56] \"25/01/2018\" \"26/01/2018\" \"27/01/2018\" \"28/01/2018\" \"29/01/2018\"\n [61] \"30/01/2018\" \"31/01/2018\" \"01/02/2018\" \"02/02/2018\" \"03/02/2018\"\n [66] \"04/02/2018\" \"05/02/2018\" \"06/02/2018\" \"07/02/2018\" \"08/02/2018\"\n [71] \"09/02/2018\" \"10/02/2018\" \"11/02/2018\" \"12/02/2018\" \"13/02/2018\"\n [76] \"14/02/2018\" \"15/02/2018\" \"16/02/2018\" \"17/02/2018\" \"18/02/2018\"\n [81] \"19/02/2018\" \"20/02/2018\" \"21/02/2018\" \"22/02/2018\" \"23/02/2018\"\n [86] \"24/02/2018\" \"25/02/2018\" \"26/02/2018\" \"27/02/2018\" \"28/02/2018\"\n [91] \"01/03/2018\" \"02/03/2018\" \"03/03/2018\" \"04/03/2018\" \"05/03/2018\"\n [96] \"06/03/2018\" \"07/03/2018\" \"08/03/2018\" \"09/03/2018\" \"10/03/2018\"\n[101] \"11/03/2018\" \"12/03/2018\" \"13/03/2018\" \"14/03/2018\" \"15/03/2018\"\n[106] \"16/03/2018\" \"17/03/2018\" \"18/03/2018\" \"19/03/2018\" \"20/03/2018\"\n[111] \"21/03/2018\" \"22/03/2018\" \"23/03/2018\" \"24/03/2018\" \"25/03/2018\"\n[116] \"26/03/2018\" \"27/03/2018\" \"28/03/2018\" \"29/03/2018\" \"30/03/2018\"\n[121] \"31/03/2018\" \"01/04/2018\" \"02/04/2018\" \"03/04/2018\" \"04/04/2018\"\n[126] \"05/04/2018\" \"06/04/2018\" \"07/04/2018\" \"08/04/2018\" \"09/04/2018\"\n[131] \"10/04/2018\" \"11/04/2018\" \"12/04/2018\" \"13/04/2018\" \"14/04/2018\"\n[136] \"15/04/2018\" \"16/04/2018\" \"17/04/2018\" \"18/04/2018\" \"19/04/2018\"\n[141] \"20/04/2018\" \"21/04/2018\" \"22/04/2018\" \"23/04/2018\" \"24/04/2018\"\n[146] \"25/04/2018\" \"26/04/2018\" \"27/04/2018\" \"28/04/2018\" \"29/04/2018\"\n[151] \"30/04/2018\" \"01/05/2018\" \"02/05/2018\" \"03/05/2018\" \"04/05/2018\"\n[156] \"05/05/2018\" \"06/05/2018\" \"07/05/2018\" \"08/05/2018\" \"09/05/2018\"\n[161] \"10/05/2018\" \"11/05/2018\" \"12/05/2018\" \"13/05/2018\" \"14/05/2018\"\n[166] \"15/05/2018\" \"16/05/2018\" \"17/05/2018\" \"18/05/2018\" \"19/05/2018\"\n[171] \"20/05/2018\" \"21/05/2018\" \"22/05/2018\" \"23/05/2018\" \"24/05/2018\"\n[176] \"25/05/2018\" \"26/05/2018\" \"27/05/2018\" \"28/05/2018\" \"29/05/2018\"\n[181] \"30/05/2018\" \"31/05/2018\" \"01/06/2018\" \"02/06/2018\" \"03/06/2018\"\n[186] \"04/06/2018\" \"05/06/2018\" \"06/06/2018\" \"07/06/2018\" \"08/06/2018\"\n[191] \"09/06/2018\" \"10/06/2018\" \"11/06/2018\" \"12/06/2018\" \"13/06/2018\"\n[196] \"14/06/2018\" \"15/06/2018\" \"16/06/2018\" \"17/06/2018\" \"18/06/2018\"\n[201] \"19/06/2018\" \"20/06/2018\" \"21/06/2018\" \"22/06/2018\" \"23/06/2018\"\n[206] \"24/06/2018\" \"25/06/2018\" \"26/06/2018\" \"27/06/2018\" \"28/06/2018\"\n[211] \"29/06/2018\" \"30/06/2018\" \"01/07/2018\" \"02/07/2018\" \"03/07/2018\"\n[216] \"04/07/2018\" \"05/07/2018\" \"06/07/2018\" \"07/07/2018\" \"08/07/2018\"\n[221] \"09/07/2018\" \"10/07/2018\" \"11/07/2018\" \"12/07/2018\" \"13/07/2018\"\n[226] \"14/07/2018\" \"15/07/2018\" \"16/07/2018\" \"17/07/2018\" \"18/07/2018\"\n[231] \"19/07/2018\" \"20/07/2018\" \"21/07/2018\" \"22/07/2018\" \"23/07/2018\"\n[236] \"24/07/2018\" \"25/07/2018\" \"26/07/2018\" \"27/07/2018\" \"28/07/2018\"\n[241] \"29/07/2018\" \"30/07/2018\" \"31/07/2018\" \"01/08/2018\" \"02/08/2018\"\n[246] \"03/08/2018\" \"04/08/2018\" \"05/08/2018\" \"06/08/2018\" \"07/08/2018\"\n[251] \"08/08/2018\" \"09/08/2018\" \"10/08/2018\" \"11/08/2018\" \"12/08/2018\"\n[256] \"13/08/2018\" \"14/08/2018\" \"15/08/2018\" \"16/08/2018\" \"17/08/2018\"\n[261] \"18/08/2018\" \"19/08/2018\" \"20/08/2018\" \"21/08/2018\" \"22/08/2018\"\n[266] \"23/08/2018\" \"24/08/2018\" \"25/08/2018\" \"26/08/2018\" \"27/08/2018\"\n[271] \"28/08/2018\" \"29/08/2018\" \"30/08/2018\" \"31/08/2018\" \"01/09/2018\"\n[276] \"02/09/2018\" \"03/09/2018\" \"04/09/2018\" \"05/09/2018\" \"06/09/2018\"\n[281] \"07/09/2018\" \"08/09/2018\" \"09/09/2018\" \"10/09/2018\" \"11/09/2018\"\n[286] \"12/09/2018\" \"13/09/2018\" \"14/09/2018\" \"15/09/2018\" \"16/09/2018\"\n[291] \"17/09/2018\" \"18/09/2018\" \"19/09/2018\" \"20/09/2018\" \"21/09/2018\"\n[296] \"22/09/2018\" \"23/09/2018\" \"24/09/2018\" \"25/09/2018\" \"26/09/2018\"\n[301] \"27/09/2018\" \"28/09/2018\" \"29/09/2018\" \"30/09/2018\" \"01/10/2018\"\n[306] \"02/10/2018\" \"03/10/2018\" \"04/10/2018\" \"05/10/2018\" \"06/10/2018\"\n[311] \"07/10/2018\" \"08/10/2018\" \"09/10/2018\" \"10/10/2018\" \"11/10/2018\"\n[316] \"12/10/2018\" \"13/10/2018\" \"14/10/2018\" \"15/10/2018\" \"16/10/2018\"\n[321] \"17/10/2018\" \"18/10/2018\" \"19/10/2018\" \"20/10/2018\" \"21/10/2018\"\n[326] \"22/10/2018\" \"23/10/2018\" \"24/10/2018\" \"25/10/2018\" \"26/10/2018\"\n[331] \"27/10/2018\" \"28/10/2018\" \"29/10/2018\" \"30/10/2018\" \"31/10/2018\"\n[336] \"01/11/2018\" \"02/11/2018\" \"03/11/2018\" \"04/11/2018\" \"05/11/2018\"\n[341] \"06/11/2018\" \"07/11/2018\" \"08/11/2018\" \"09/11/2018\" \"10/11/2018\"\n[346] \"11/11/2018\" \"12/11/2018\" \"13/11/2018\" \"14/11/2018\" \"15/11/2018\"\n[351] \"16/11/2018\" \"17/11/2018\" \"18/11/2018\" \"19/11/2018\" \"20/11/2018\"\n[356] \"21/11/2018\" \"22/11/2018\" \"23/11/2018\" \"24/11/2018\" \"25/11/2018\"\n[361] \"26/11/2018\" \"27/11/2018\" \"28/11/2018\" \"29/11/2018\" \"30/11/2018\"\n\n$Seasons\n[1] \"Winter\" \"Spring\" \"Summer\" \"Autumn\"\n\n$Holiday\n[1] \"No Holiday\" \"Holiday\"   \n\n$`Functioning Day`\n[1] \"Yes\" \"No\" \n\n\nDealing with the date column, convert it into proper lubridate format.\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\ndf$Date &lt;- dmy(df$Date)\n\n\ndf$Seasons&lt;-as.factor(df$Seasons)\ndf$\"Functioning Day\"&lt;-as.factor(df$\"Functioning Day\")\ndf$Holiday&lt;-as.factor(df$Holiday)\n\nChecking these out, make sure it all looks ok.\n\nunique(df$Seasons)\n\n[1] Winter Spring Summer Autumn\nLevels: Autumn Spring Summer Winter\n\nunique(df$\"Functioning Day\")\n\n[1] Yes No \nLevels: No Yes\n\nunique(df$Holiday)\n\n[1] No Holiday Holiday   \nLevels: Holiday No Holiday\n\n\nRenaming columns for ease of referencing. Want to do this in one go, so I’m going to try to use the janitor package to do this.\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\ndf &lt;- df |&gt;\n  janitor::clean_names()\ncolnames(df)\n\n [1] \"date\"                    \"rented_bike_count\"      \n [3] \"hour\"                    \"temperature_c\"          \n [5] \"humidity_percent\"        \"wind_speed_m_s\"         \n [7] \"visibility_10m\"          \"dew_point_temperature_c\"\n [9] \"solar_radiation_mj_m2\"   \"rainfall_mm\"            \n[11] \"snowfall_cm\"             \"seasons\"                \n[13] \"holiday\"                 \"functioning_day\"        \n\n\nThat looks really nice. Thanks Janitor!\nNext, I’d like to look at some summary statistics\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\ndf |&gt;  \n  group_by(functioning_day) |&gt;  \n  summarise(\n    mean_bikes = mean(rented_bike_count),\n    median_bikes = median(rented_bike_count)\n  )\n\n# A tibble: 2 × 3\n  functioning_day mean_bikes median_bikes\n  &lt;fct&gt;                &lt;dbl&gt;        &lt;dbl&gt;\n1 No                      0             0\n2 Yes                   729.          542\n\n\nFunctioning day is odd–I think it means if the bike service was functional or not. This would explain why no bikes are rented on days when it is no. We should probably throw out the no cases, they won’t be helpful or insightful to our analysis.\n\ndf_subset&lt;-df|&gt;\n  filter(functioning_day==\"Yes\")\n\nLet’s look at some more statistics for this subsetted dataset.\n\ndf_subset |&gt;  \n  group_by(seasons) |&gt;  \n  summarise(\n    mean_bikes = mean(rented_bike_count),\n    median_bikes = median(rented_bike_count)\n  )\n\n# A tibble: 4 × 3\n  seasons mean_bikes median_bikes\n  &lt;fct&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 Autumn        924.         856 \n2 Spring        746.         599 \n3 Summer       1034.         906.\n4 Winter        226.         203 \n\ndf_subset |&gt;  \n  group_by(holiday) |&gt;  \n  summarise(\n    mean_bikes = mean(rented_bike_count),\n    median_bikes = median(rented_bike_count)\n  )\n\n# A tibble: 2 × 3\n  holiday    mean_bikes median_bikes\n  &lt;fct&gt;           &lt;dbl&gt;        &lt;dbl&gt;\n1 Holiday          529.          259\n2 No Holiday       739.          561\n\n\nNow, I’m going to aggregate all the hourly data into the day column, along with season and holiday as specified in the document\n\ndf_daily &lt;- df |&gt;\n  group_by(date, seasons, holiday) |&gt;\n  summarise(\n    total_bikes = sum(rented_bike_count),\n    total_rainfall = sum(rainfall_mm),\n    total_snowfall = sum(snowfall_cm),\n    mean_temperature = mean(temperature_c),\n    mean_humidity = mean(humidity_percent),\n    mean_wind_speed = mean(wind_speed_m_s)\n  )\n\n`summarise()` has grouped output by 'date', 'seasons'. You can override using\nthe `.groups` argument.\n\n\nMake sure that our new aggregated df looks ok.\n\ndf_daily\n\n# A tibble: 365 × 9\n# Groups:   date, seasons [365]\n   date       seasons holiday    total_bikes total_rainfall total_snowfall\n   &lt;date&gt;     &lt;fct&gt;   &lt;fct&gt;            &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;\n 1 2017-12-01 Winter  No Holiday        9539            0              0  \n 2 2017-12-02 Winter  No Holiday        8523            0              0  \n 3 2017-12-03 Winter  No Holiday        7222            4              0  \n 4 2017-12-04 Winter  No Holiday        8729            0.1            0  \n 5 2017-12-05 Winter  No Holiday        8307            0              0  \n 6 2017-12-06 Winter  No Holiday        6669            1.3            8.6\n 7 2017-12-07 Winter  No Holiday        8549            0             10.4\n 8 2017-12-08 Winter  No Holiday        8032            0              0  \n 9 2017-12-09 Winter  No Holiday        7233            0              0  \n10 2017-12-10 Winter  No Holiday        3453            4.1           32.5\n# ℹ 355 more rows\n# ℹ 3 more variables: mean_temperature &lt;dbl&gt;, mean_humidity &lt;dbl&gt;,\n#   mean_wind_speed &lt;dbl&gt;\n\n\nThat looks ok.\n\n\n\nI’m primarily interested to see how weather affects bike rentals.\nLet’s look at some summary stats for categorical variables.\n\ndf_daily |&gt;  \n  group_by(seasons) |&gt;  \n  summarise(\n    mean_bikes = mean(total_bikes),\n    median_bikes = median(total_bikes)\n  )\n\n# A tibble: 4 × 3\n  seasons mean_bikes median_bikes\n  &lt;fct&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 Autumn      19670.       21545 \n2 Spring      17521.       17419 \n3 Summer      24818.       25572.\n4 Winter       5413.        5498 \n\n\n\ndf_daily |&gt;  \n  group_by(holiday) |&gt;  \n  summarise(\n    mean_bikes = mean(total_bikes),\n    median_bikes = median(total_bikes)\n  )\n\n# A tibble: 2 × 3\n  holiday    mean_bikes median_bikes\n  &lt;fct&gt;           &lt;dbl&gt;        &lt;dbl&gt;\n1 Holiday        11994.         6158\n2 No Holiday     17165.        18363\n\n\nInteresting, I would have initially guessed it is the opposite, but it must be related to work commuters.\nLet’s look at the relationship between weather variables and bikes rented next.\n\n\n\n\nlibrary(ggplot2)\n\nggplot(df_daily,aes(x=total_rainfall, y=total_bikes))+\n  geom_point()+\n  labs(\n    x=\"Rainfall (mm)\",\n    y=\"Total Bikes Rented\"\n  )\n\n\n\ncor(df_daily$total_bikes, df_daily$total_rainfall)\n\n[1] -0.2142524\n\n\n\n\n\n\nggplot(df_daily,aes(x=total_snowfall, y=total_bikes))+\n  geom_point()+\n  labs(\n    x=\"Snowfall (cm)\",\n    y=\"Total Bikes Rented\"\n  )\n\n\n\ncor(df_daily$total_bikes, df_daily$total_snowfall)\n\n[1] -0.240836\n\n\n\n\n\n\nggplot(df_daily,aes(x=mean_temperature, y=total_bikes))+\n  geom_point()+\n  labs(\n    x=\"Temp (C)\",\n    y=\"Total Bikes Rented\"\n  )\n\n\n\ncor(df_daily$total_bikes, df_daily$mean_temperature)\n\n[1] 0.6998242\n\n\n\n\n\n\nggplot(df_daily,aes(x=mean_wind_speed, y=total_bikes))+\n  geom_point()+\n  labs(\n    x=\"Wind Speed\",\n    y=\"Total Bikes Rented\"\n  )\n\n\n\ncor(df_daily$total_bikes, df_daily$mean_wind_speed)\n\n[1] -0.1748594\n\n\nI just want to check out some correlations between numeric variables. I bet temperature and snow are related. Maybe temperature and wind speed as well.\n\nggplot(df_daily,aes(x=mean_temperature, y=total_snowfall))+\n  geom_point()+\n  labs(\n    x=\"Temperature\",\n    y=\"Snowfall\"\n  )\n\n\n\n\n\nggplot(df_daily,aes(x=mean_temperature, y=mean_wind_speed))+\n  geom_point()+\n  labs(\n    x=\"Temperature\",\n    y=\"Wind Speed\"\n  )\n\n\n\n\nThere is less correlation between weather variables than what I expected. But there is correlation between some of the weather variables and bikes rented.\n\n\n\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.4.1 ──\n\n\n✔ broom        1.0.10     ✔ rsample      1.3.1 \n✔ dials        1.4.2      ✔ tailor       0.1.0 \n✔ infer        1.0.9      ✔ tune         2.0.1 \n✔ modeldata    1.5.1      ✔ workflows    1.3.0 \n✔ parsnip      1.3.3      ✔ workflowsets 1.1.1 \n✔ purrr        1.2.0      ✔ yardstick    1.3.2 \n✔ recipes      1.3.1      \n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard()  masks scales::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\n# From https://www.tidymodels.org/start/recipes/#data-split\n\nset.seed(222)\n# Put 3/4 of the data into the training set \ndata_split &lt;- initial_split(df_daily, prop = 3/4, strata=seasons)\n\n# Create data frames for the two sets:\ntrain_data &lt;- training(data_split)\ntest_data  &lt;- testing(data_split)\n\n\n#check\ndim(test_data)\n\n[1] 92  9\n\ndim(train_data)\n\n[1] 273   9\n\n\n\n\n\n\nset.seed(222)\nfolds &lt;- vfold_cv(train_data, v = 10)\n\n\n\n\n\ncolnames(train_data)\n\n[1] \"date\"             \"seasons\"          \"holiday\"          \"total_bikes\"     \n[5] \"total_rainfall\"   \"total_snowfall\"   \"mean_temperature\" \"mean_humidity\"   \n[9] \"mean_wind_speed\" \n\n\n\nbike_recipe &lt;- recipe(total_bikes ~ ., data = train_data) |&gt;\n  # extract date features\n  step_date(date, features = c(\"dow\")) |&gt;   # adds \"date_dow\" = day of week\n  \n  # create weekday/weekend variable\n  step_mutate(\n    day_type = factor(if_else(date_dow %in% c(\"Sat\", \"Sun\"), \"weekend\", \"weekday\"))\n  ) |&gt;\n  \n  # remove intermediate day-of-week variable\n  step_rm(date, date_dow) |&gt;\n  \n  # standardize (normalize) numeric variables\n  step_normalize(all_numeric_predictors()) |&gt;\n  \n  # create dummy variables for categorical predictors\n  step_dummy(all_nominal_predictors())\n\n\n\n\n\nbike_recipe2 &lt;- recipe(total_bikes ~ ., data = train_data) |&gt;\n  # extract date features\n  step_date(date, features = c(\"dow\")) |&gt;   # adds \"date_dow\" = day of week\n  \n  # create weekday/weekend variable\n  step_mutate(\n    day_type = factor(if_else(date_dow %in% c(\"Sat\", \"Sun\"), \"weekend\", \"weekday\"))\n  ) |&gt;\n  \n  # remove intermediate day-of-week variable\n  step_rm(date, date_dow) |&gt;\n  \n  # standardize (normalize) numeric variables\n  step_normalize(all_numeric_predictors()) |&gt;\n  \n  # create dummy variables for categorical predictors\n  step_dummy(all_nominal_predictors())|&gt;\n\n  # adding in the proper interactions\n  step_interact(~ starts_with(\"seasons\"):starts_with(\"holiday\"))|&gt;\n  step_interact(~starts_with(\"seasons\"):mean_temperature)|&gt;\n  step_interact(~total_rainfall:mean_temperature)\n\n\n\n\n\nbike_recipe3 &lt;- recipe(total_bikes ~ ., data = train_data) |&gt;\n  # extract date features\n  step_date(date, features = c(\"dow\")) |&gt;   # adds \"date_dow\" = day of week\n  \n  # create weekday/weekend variable\n  step_mutate(\n    day_type = factor(if_else(date_dow %in% c(\"Sat\", \"Sun\"), \"weekend\", \"weekday\"))\n  ) |&gt;\n  \n  # remove intermediate day-of-week variable\n  step_rm(date, date_dow) |&gt;\n  \n  # standardize (normalize) numeric variables\n  step_normalize(all_numeric_predictors()) |&gt;\n  \n  # create dummy variables for categorical predictors\n  step_dummy(all_nominal_predictors())|&gt;\n\n  # adding in the proper interactions\n  step_interact(~starts_with(\"seasons\"):starts_with(\"holiday\"))|&gt;\n  step_interact(~starts_with(\"seasons\"):mean_temperature)|&gt;\n  step_interact(~total_rainfall:mean_temperature)|&gt;\n\n  #create quadratic terms\n  step_poly(c(total_rainfall,total_snowfall,mean_temperature,mean_humidity,mean_wind_speed), degree = 2)\n\n\n\n\n\nlm_model &lt;- linear_reg() |&gt; \n  set_engine(\"lm\")\n\n\n\n\n\nbike_wf1 &lt;- workflow() |&gt;\n  add_model(lm_model) |&gt;\n  add_recipe(bike_recipe)\n\nbike_wf2 &lt;- workflow() |&gt;\n  add_model(lm_model) |&gt;\n  add_recipe(bike_recipe2)\n\nbike_wf3 &lt;- workflow() |&gt;\n  add_model(lm_model) |&gt;\n  add_recipe(bike_recipe3)\n\n\n\n\n\n\n\nbike_res1&lt;-fit_resamples(\n  bike_wf1,\n  resamples = folds,\n  metrics = metric_set(rmse, rsq),\n)\ncollect_metrics(bike_res1)\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config        \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard   6081.       10 491.     pre0_mod0_post0\n2 rsq     standard      0.649    10   0.0455 pre0_mod0_post0\n\n\n\n\n\n\nbike_res2&lt;-fit_resamples(\n  bike_wf2,\n  resamples = folds,\n  metrics = metric_set(rmse, rsq),\n)\n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x1\n\n\nThere were issues with some computations   A: x3\n\n\nThere were issues with some computations   A: x9\n\n\nThere were issues with some computations   A: x10\n\n\n\n\ncollect_metrics(bike_res2)\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config        \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard   5486.       10 467.     pre0_mod0_post0\n2 rsq     standard      0.706    10   0.0413 pre0_mod0_post0\n\n\n\n\n\n\nbike_res3&lt;-fit_resamples(\n  bike_wf3,\n  resamples = folds,\n  metrics = metric_set(rmse, rsq),\n)\n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x4\n\n\nThere were issues with some computations   A: x9\n\n\nThere were issues with some computations   A: x10\n\n\n\n\ncollect_metrics(bike_res3)\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config        \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard   5455.       10 477.     pre0_mod0_post0\n2 rsq     standard      0.711    10   0.0418 pre0_mod0_post0\n\n\n\n\n\n\n\nI will select the first model, it had the lowest RMSE.\n\n\n\nI will show the final model fit and the associated metrics.\n\n\nfinal_fit &lt;- last_fit(bike_wf1, split = data_split)\n\n\ncollect_metrics(final_fit)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config        \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard    6139.    pre0_mod0_post0\n2 rsq     standard       0.617 pre0_mod0_post0\n\n\n\n\n\n\nfinal_model &lt;- final_fit |&gt;\n  extract_fit_parsnip()\ntidy(final_model)\n\n# A tibble: 11 × 5\n   term               estimate std.error statistic  p.value\n   &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)        14715.       1913.    7.69   2.92e-13\n 2 total_rainfall     -2466.        459.   -5.38   1.68e- 7\n 3 total_snowfall         6.10      412.    0.0148 9.88e- 1\n 4 mean_temperature    5194.        887.    5.86   1.41e- 8\n 5 mean_humidity      -2271.        513.   -4.43   1.41e- 5\n 6 mean_wind_speed     -262.        405.   -0.647  5.18e- 1\n 7 seasons_Spring     -1570.       1092.   -1.44   1.52e- 1\n 8 seasons_Summer      2160.       1397.    1.55   1.23e- 1\n 9 seasons_Winter     -7774.       1650.   -4.71   3.99e- 6\n10 holiday_No.Holiday  4322.       1851.    2.33   2.03e- 2\n11 day_type_weekend   -1393.        831.   -1.68   9.48e- 2"
  },
  {
    "objectID": "hw8.html#data-cleaning",
    "href": "hw8.html#data-cleaning",
    "title": "Homework 8",
    "section": "",
    "text": "I’d like to check for missingness.\n\nsum(is.na(df))\n\n[1] 0\n\n\nNo missing data. That’s good!\n\nsummary(df)\n\n     Date           Rented Bike Count      Hour       Temperature(°C) \n Length:8760        Min.   :   0.0    Min.   : 0.00   Min.   :-17.80  \n Class :character   1st Qu.: 191.0    1st Qu.: 5.75   1st Qu.:  3.50  \n Mode  :character   Median : 504.5    Median :11.50   Median : 13.70  \n                    Mean   : 704.6    Mean   :11.50   Mean   : 12.88  \n                    3rd Qu.:1065.2    3rd Qu.:17.25   3rd Qu.: 22.50  \n                    Max.   :3556.0    Max.   :23.00   Max.   : 39.40  \n  Humidity(%)    Wind speed (m/s) Visibility (10m) Dew point temperature(°C)\n Min.   : 0.00   Min.   :0.000    Min.   :  27     Min.   :-30.600          \n 1st Qu.:42.00   1st Qu.:0.900    1st Qu.: 940     1st Qu.: -4.700          \n Median :57.00   Median :1.500    Median :1698     Median :  5.100          \n Mean   :58.23   Mean   :1.725    Mean   :1437     Mean   :  4.074          \n 3rd Qu.:74.00   3rd Qu.:2.300    3rd Qu.:2000     3rd Qu.: 14.800          \n Max.   :98.00   Max.   :7.400    Max.   :2000     Max.   : 27.200          \n Solar Radiation (MJ/m2)  Rainfall(mm)     Snowfall (cm)       Seasons         \n Min.   :0.0000          Min.   : 0.0000   Min.   :0.00000   Length:8760       \n 1st Qu.:0.0000          1st Qu.: 0.0000   1st Qu.:0.00000   Class :character  \n Median :0.0100          Median : 0.0000   Median :0.00000   Mode  :character  \n Mean   :0.5691          Mean   : 0.1487   Mean   :0.07507                     \n 3rd Qu.:0.9300          3rd Qu.: 0.0000   3rd Qu.:0.00000                     \n Max.   :3.5200          Max.   :35.0000   Max.   :8.80000                     \n   Holiday          Functioning Day   \n Length:8760        Length:8760       \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n                                      \n                                      \n                                      \n\n\nCheck unique values in character columns\n\nlapply(df[sapply(df, is.character)], unique)\n\n$Date\n  [1] \"01/12/2017\" \"02/12/2017\" \"03/12/2017\" \"04/12/2017\" \"05/12/2017\"\n  [6] \"06/12/2017\" \"07/12/2017\" \"08/12/2017\" \"09/12/2017\" \"10/12/2017\"\n [11] \"11/12/2017\" \"12/12/2017\" \"13/12/2017\" \"14/12/2017\" \"15/12/2017\"\n [16] \"16/12/2017\" \"17/12/2017\" \"18/12/2017\" \"19/12/2017\" \"20/12/2017\"\n [21] \"21/12/2017\" \"22/12/2017\" \"23/12/2017\" \"24/12/2017\" \"25/12/2017\"\n [26] \"26/12/2017\" \"27/12/2017\" \"28/12/2017\" \"29/12/2017\" \"30/12/2017\"\n [31] \"31/12/2017\" \"01/01/2018\" \"02/01/2018\" \"03/01/2018\" \"04/01/2018\"\n [36] \"05/01/2018\" \"06/01/2018\" \"07/01/2018\" \"08/01/2018\" \"09/01/2018\"\n [41] \"10/01/2018\" \"11/01/2018\" \"12/01/2018\" \"13/01/2018\" \"14/01/2018\"\n [46] \"15/01/2018\" \"16/01/2018\" \"17/01/2018\" \"18/01/2018\" \"19/01/2018\"\n [51] \"20/01/2018\" \"21/01/2018\" \"22/01/2018\" \"23/01/2018\" \"24/01/2018\"\n [56] \"25/01/2018\" \"26/01/2018\" \"27/01/2018\" \"28/01/2018\" \"29/01/2018\"\n [61] \"30/01/2018\" \"31/01/2018\" \"01/02/2018\" \"02/02/2018\" \"03/02/2018\"\n [66] \"04/02/2018\" \"05/02/2018\" \"06/02/2018\" \"07/02/2018\" \"08/02/2018\"\n [71] \"09/02/2018\" \"10/02/2018\" \"11/02/2018\" \"12/02/2018\" \"13/02/2018\"\n [76] \"14/02/2018\" \"15/02/2018\" \"16/02/2018\" \"17/02/2018\" \"18/02/2018\"\n [81] \"19/02/2018\" \"20/02/2018\" \"21/02/2018\" \"22/02/2018\" \"23/02/2018\"\n [86] \"24/02/2018\" \"25/02/2018\" \"26/02/2018\" \"27/02/2018\" \"28/02/2018\"\n [91] \"01/03/2018\" \"02/03/2018\" \"03/03/2018\" \"04/03/2018\" \"05/03/2018\"\n [96] \"06/03/2018\" \"07/03/2018\" \"08/03/2018\" \"09/03/2018\" \"10/03/2018\"\n[101] \"11/03/2018\" \"12/03/2018\" \"13/03/2018\" \"14/03/2018\" \"15/03/2018\"\n[106] \"16/03/2018\" \"17/03/2018\" \"18/03/2018\" \"19/03/2018\" \"20/03/2018\"\n[111] \"21/03/2018\" \"22/03/2018\" \"23/03/2018\" \"24/03/2018\" \"25/03/2018\"\n[116] \"26/03/2018\" \"27/03/2018\" \"28/03/2018\" \"29/03/2018\" \"30/03/2018\"\n[121] \"31/03/2018\" \"01/04/2018\" \"02/04/2018\" \"03/04/2018\" \"04/04/2018\"\n[126] \"05/04/2018\" \"06/04/2018\" \"07/04/2018\" \"08/04/2018\" \"09/04/2018\"\n[131] \"10/04/2018\" \"11/04/2018\" \"12/04/2018\" \"13/04/2018\" \"14/04/2018\"\n[136] \"15/04/2018\" \"16/04/2018\" \"17/04/2018\" \"18/04/2018\" \"19/04/2018\"\n[141] \"20/04/2018\" \"21/04/2018\" \"22/04/2018\" \"23/04/2018\" \"24/04/2018\"\n[146] \"25/04/2018\" \"26/04/2018\" \"27/04/2018\" \"28/04/2018\" \"29/04/2018\"\n[151] \"30/04/2018\" \"01/05/2018\" \"02/05/2018\" \"03/05/2018\" \"04/05/2018\"\n[156] \"05/05/2018\" \"06/05/2018\" \"07/05/2018\" \"08/05/2018\" \"09/05/2018\"\n[161] \"10/05/2018\" \"11/05/2018\" \"12/05/2018\" \"13/05/2018\" \"14/05/2018\"\n[166] \"15/05/2018\" \"16/05/2018\" \"17/05/2018\" \"18/05/2018\" \"19/05/2018\"\n[171] \"20/05/2018\" \"21/05/2018\" \"22/05/2018\" \"23/05/2018\" \"24/05/2018\"\n[176] \"25/05/2018\" \"26/05/2018\" \"27/05/2018\" \"28/05/2018\" \"29/05/2018\"\n[181] \"30/05/2018\" \"31/05/2018\" \"01/06/2018\" \"02/06/2018\" \"03/06/2018\"\n[186] \"04/06/2018\" \"05/06/2018\" \"06/06/2018\" \"07/06/2018\" \"08/06/2018\"\n[191] \"09/06/2018\" \"10/06/2018\" \"11/06/2018\" \"12/06/2018\" \"13/06/2018\"\n[196] \"14/06/2018\" \"15/06/2018\" \"16/06/2018\" \"17/06/2018\" \"18/06/2018\"\n[201] \"19/06/2018\" \"20/06/2018\" \"21/06/2018\" \"22/06/2018\" \"23/06/2018\"\n[206] \"24/06/2018\" \"25/06/2018\" \"26/06/2018\" \"27/06/2018\" \"28/06/2018\"\n[211] \"29/06/2018\" \"30/06/2018\" \"01/07/2018\" \"02/07/2018\" \"03/07/2018\"\n[216] \"04/07/2018\" \"05/07/2018\" \"06/07/2018\" \"07/07/2018\" \"08/07/2018\"\n[221] \"09/07/2018\" \"10/07/2018\" \"11/07/2018\" \"12/07/2018\" \"13/07/2018\"\n[226] \"14/07/2018\" \"15/07/2018\" \"16/07/2018\" \"17/07/2018\" \"18/07/2018\"\n[231] \"19/07/2018\" \"20/07/2018\" \"21/07/2018\" \"22/07/2018\" \"23/07/2018\"\n[236] \"24/07/2018\" \"25/07/2018\" \"26/07/2018\" \"27/07/2018\" \"28/07/2018\"\n[241] \"29/07/2018\" \"30/07/2018\" \"31/07/2018\" \"01/08/2018\" \"02/08/2018\"\n[246] \"03/08/2018\" \"04/08/2018\" \"05/08/2018\" \"06/08/2018\" \"07/08/2018\"\n[251] \"08/08/2018\" \"09/08/2018\" \"10/08/2018\" \"11/08/2018\" \"12/08/2018\"\n[256] \"13/08/2018\" \"14/08/2018\" \"15/08/2018\" \"16/08/2018\" \"17/08/2018\"\n[261] \"18/08/2018\" \"19/08/2018\" \"20/08/2018\" \"21/08/2018\" \"22/08/2018\"\n[266] \"23/08/2018\" \"24/08/2018\" \"25/08/2018\" \"26/08/2018\" \"27/08/2018\"\n[271] \"28/08/2018\" \"29/08/2018\" \"30/08/2018\" \"31/08/2018\" \"01/09/2018\"\n[276] \"02/09/2018\" \"03/09/2018\" \"04/09/2018\" \"05/09/2018\" \"06/09/2018\"\n[281] \"07/09/2018\" \"08/09/2018\" \"09/09/2018\" \"10/09/2018\" \"11/09/2018\"\n[286] \"12/09/2018\" \"13/09/2018\" \"14/09/2018\" \"15/09/2018\" \"16/09/2018\"\n[291] \"17/09/2018\" \"18/09/2018\" \"19/09/2018\" \"20/09/2018\" \"21/09/2018\"\n[296] \"22/09/2018\" \"23/09/2018\" \"24/09/2018\" \"25/09/2018\" \"26/09/2018\"\n[301] \"27/09/2018\" \"28/09/2018\" \"29/09/2018\" \"30/09/2018\" \"01/10/2018\"\n[306] \"02/10/2018\" \"03/10/2018\" \"04/10/2018\" \"05/10/2018\" \"06/10/2018\"\n[311] \"07/10/2018\" \"08/10/2018\" \"09/10/2018\" \"10/10/2018\" \"11/10/2018\"\n[316] \"12/10/2018\" \"13/10/2018\" \"14/10/2018\" \"15/10/2018\" \"16/10/2018\"\n[321] \"17/10/2018\" \"18/10/2018\" \"19/10/2018\" \"20/10/2018\" \"21/10/2018\"\n[326] \"22/10/2018\" \"23/10/2018\" \"24/10/2018\" \"25/10/2018\" \"26/10/2018\"\n[331] \"27/10/2018\" \"28/10/2018\" \"29/10/2018\" \"30/10/2018\" \"31/10/2018\"\n[336] \"01/11/2018\" \"02/11/2018\" \"03/11/2018\" \"04/11/2018\" \"05/11/2018\"\n[341] \"06/11/2018\" \"07/11/2018\" \"08/11/2018\" \"09/11/2018\" \"10/11/2018\"\n[346] \"11/11/2018\" \"12/11/2018\" \"13/11/2018\" \"14/11/2018\" \"15/11/2018\"\n[351] \"16/11/2018\" \"17/11/2018\" \"18/11/2018\" \"19/11/2018\" \"20/11/2018\"\n[356] \"21/11/2018\" \"22/11/2018\" \"23/11/2018\" \"24/11/2018\" \"25/11/2018\"\n[361] \"26/11/2018\" \"27/11/2018\" \"28/11/2018\" \"29/11/2018\" \"30/11/2018\"\n\n$Seasons\n[1] \"Winter\" \"Spring\" \"Summer\" \"Autumn\"\n\n$Holiday\n[1] \"No Holiday\" \"Holiday\"   \n\n$`Functioning Day`\n[1] \"Yes\" \"No\" \n\n\nDealing with the date column, convert it into proper lubridate format.\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\ndf$Date &lt;- dmy(df$Date)\n\n\ndf$Seasons&lt;-as.factor(df$Seasons)\ndf$\"Functioning Day\"&lt;-as.factor(df$\"Functioning Day\")\ndf$Holiday&lt;-as.factor(df$Holiday)\n\nChecking these out, make sure it all looks ok.\n\nunique(df$Seasons)\n\n[1] Winter Spring Summer Autumn\nLevels: Autumn Spring Summer Winter\n\nunique(df$\"Functioning Day\")\n\n[1] Yes No \nLevels: No Yes\n\nunique(df$Holiday)\n\n[1] No Holiday Holiday   \nLevels: Holiday No Holiday\n\n\nRenaming columns for ease of referencing. Want to do this in one go, so I’m going to try to use the janitor package to do this.\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\ndf &lt;- df |&gt;\n  janitor::clean_names()\ncolnames(df)\n\n [1] \"date\"                    \"rented_bike_count\"      \n [3] \"hour\"                    \"temperature_c\"          \n [5] \"humidity_percent\"        \"wind_speed_m_s\"         \n [7] \"visibility_10m\"          \"dew_point_temperature_c\"\n [9] \"solar_radiation_mj_m2\"   \"rainfall_mm\"            \n[11] \"snowfall_cm\"             \"seasons\"                \n[13] \"holiday\"                 \"functioning_day\"        \n\n\nThat looks really nice. Thanks Janitor!\nNext, I’d like to look at some summary statistics\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\ndf |&gt;  \n  group_by(functioning_day) |&gt;  \n  summarise(\n    mean_bikes = mean(rented_bike_count),\n    median_bikes = median(rented_bike_count)\n  )\n\n# A tibble: 2 × 3\n  functioning_day mean_bikes median_bikes\n  &lt;fct&gt;                &lt;dbl&gt;        &lt;dbl&gt;\n1 No                      0             0\n2 Yes                   729.          542\n\n\nFunctioning day is odd–I think it means if the bike service was functional or not. This would explain why no bikes are rented on days when it is no. We should probably throw out the no cases, they won’t be helpful or insightful to our analysis.\n\ndf_subset&lt;-df|&gt;\n  filter(functioning_day==\"Yes\")\n\nLet’s look at some more statistics for this subsetted dataset.\n\ndf_subset |&gt;  \n  group_by(seasons) |&gt;  \n  summarise(\n    mean_bikes = mean(rented_bike_count),\n    median_bikes = median(rented_bike_count)\n  )\n\n# A tibble: 4 × 3\n  seasons mean_bikes median_bikes\n  &lt;fct&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 Autumn        924.         856 \n2 Spring        746.         599 \n3 Summer       1034.         906.\n4 Winter        226.         203 \n\ndf_subset |&gt;  \n  group_by(holiday) |&gt;  \n  summarise(\n    mean_bikes = mean(rented_bike_count),\n    median_bikes = median(rented_bike_count)\n  )\n\n# A tibble: 2 × 3\n  holiday    mean_bikes median_bikes\n  &lt;fct&gt;           &lt;dbl&gt;        &lt;dbl&gt;\n1 Holiday          529.          259\n2 No Holiday       739.          561\n\n\nNow, I’m going to aggregate all the hourly data into the day column, along with season and holiday as specified in the document\n\ndf_daily &lt;- df |&gt;\n  group_by(date, seasons, holiday) |&gt;\n  summarise(\n    total_bikes = sum(rented_bike_count),\n    total_rainfall = sum(rainfall_mm),\n    total_snowfall = sum(snowfall_cm),\n    mean_temperature = mean(temperature_c),\n    mean_humidity = mean(humidity_percent),\n    mean_wind_speed = mean(wind_speed_m_s)\n  )\n\n`summarise()` has grouped output by 'date', 'seasons'. You can override using\nthe `.groups` argument.\n\n\nMake sure that our new aggregated df looks ok.\n\ndf_daily\n\n# A tibble: 365 × 9\n# Groups:   date, seasons [365]\n   date       seasons holiday    total_bikes total_rainfall total_snowfall\n   &lt;date&gt;     &lt;fct&gt;   &lt;fct&gt;            &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;\n 1 2017-12-01 Winter  No Holiday        9539            0              0  \n 2 2017-12-02 Winter  No Holiday        8523            0              0  \n 3 2017-12-03 Winter  No Holiday        7222            4              0  \n 4 2017-12-04 Winter  No Holiday        8729            0.1            0  \n 5 2017-12-05 Winter  No Holiday        8307            0              0  \n 6 2017-12-06 Winter  No Holiday        6669            1.3            8.6\n 7 2017-12-07 Winter  No Holiday        8549            0             10.4\n 8 2017-12-08 Winter  No Holiday        8032            0              0  \n 9 2017-12-09 Winter  No Holiday        7233            0              0  \n10 2017-12-10 Winter  No Holiday        3453            4.1           32.5\n# ℹ 355 more rows\n# ℹ 3 more variables: mean_temperature &lt;dbl&gt;, mean_humidity &lt;dbl&gt;,\n#   mean_wind_speed &lt;dbl&gt;\n\n\nThat looks ok."
  },
  {
    "objectID": "hw8.html#data-exploration",
    "href": "hw8.html#data-exploration",
    "title": "Homework 8",
    "section": "",
    "text": "I’m primarily interested to see how weather affects bike rentals.\nLet’s look at some summary stats for categorical variables.\n\ndf_daily |&gt;  \n  group_by(seasons) |&gt;  \n  summarise(\n    mean_bikes = mean(total_bikes),\n    median_bikes = median(total_bikes)\n  )\n\n# A tibble: 4 × 3\n  seasons mean_bikes median_bikes\n  &lt;fct&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 Autumn      19670.       21545 \n2 Spring      17521.       17419 \n3 Summer      24818.       25572.\n4 Winter       5413.        5498 \n\n\n\ndf_daily |&gt;  \n  group_by(holiday) |&gt;  \n  summarise(\n    mean_bikes = mean(total_bikes),\n    median_bikes = median(total_bikes)\n  )\n\n# A tibble: 2 × 3\n  holiday    mean_bikes median_bikes\n  &lt;fct&gt;           &lt;dbl&gt;        &lt;dbl&gt;\n1 Holiday        11994.         6158\n2 No Holiday     17165.        18363\n\n\nInteresting, I would have initially guessed it is the opposite, but it must be related to work commuters.\nLet’s look at the relationship between weather variables and bikes rented next."
  },
  {
    "objectID": "hw8.html#rainfall",
    "href": "hw8.html#rainfall",
    "title": "Homework 8",
    "section": "",
    "text": "library(ggplot2)\n\nggplot(df_daily,aes(x=total_rainfall, y=total_bikes))+\n  geom_point()+\n  labs(\n    x=\"Rainfall (mm)\",\n    y=\"Total Bikes Rented\"\n  )\n\n\n\ncor(df_daily$total_bikes, df_daily$total_rainfall)\n\n[1] -0.2142524"
  },
  {
    "objectID": "hw8.html#snow",
    "href": "hw8.html#snow",
    "title": "Homework 8",
    "section": "",
    "text": "ggplot(df_daily,aes(x=total_snowfall, y=total_bikes))+\n  geom_point()+\n  labs(\n    x=\"Snowfall (cm)\",\n    y=\"Total Bikes Rented\"\n  )\n\n\n\ncor(df_daily$total_bikes, df_daily$total_snowfall)\n\n[1] -0.240836"
  },
  {
    "objectID": "hw8.html#temperature",
    "href": "hw8.html#temperature",
    "title": "Homework 8",
    "section": "",
    "text": "ggplot(df_daily,aes(x=mean_temperature, y=total_bikes))+\n  geom_point()+\n  labs(\n    x=\"Temp (C)\",\n    y=\"Total Bikes Rented\"\n  )\n\n\n\ncor(df_daily$total_bikes, df_daily$mean_temperature)\n\n[1] 0.6998242"
  },
  {
    "objectID": "hw8.html#wind-speed",
    "href": "hw8.html#wind-speed",
    "title": "Homework 8",
    "section": "",
    "text": "ggplot(df_daily,aes(x=mean_wind_speed, y=total_bikes))+\n  geom_point()+\n  labs(\n    x=\"Wind Speed\",\n    y=\"Total Bikes Rented\"\n  )\n\n\n\ncor(df_daily$total_bikes, df_daily$mean_wind_speed)\n\n[1] -0.1748594\n\n\nI just want to check out some correlations between numeric variables. I bet temperature and snow are related. Maybe temperature and wind speed as well.\n\nggplot(df_daily,aes(x=mean_temperature, y=total_snowfall))+\n  geom_point()+\n  labs(\n    x=\"Temperature\",\n    y=\"Snowfall\"\n  )\n\n\n\n\n\nggplot(df_daily,aes(x=mean_temperature, y=mean_wind_speed))+\n  geom_point()+\n  labs(\n    x=\"Temperature\",\n    y=\"Wind Speed\"\n  )\n\n\n\n\nThere is less correlation between weather variables than what I expected. But there is correlation between some of the weather variables and bikes rented."
  },
  {
    "objectID": "hw8.html#splitting-the-data",
    "href": "hw8.html#splitting-the-data",
    "title": "Homework 8",
    "section": "",
    "text": "library(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.4.1 ──\n\n\n✔ broom        1.0.10     ✔ rsample      1.3.1 \n✔ dials        1.4.2      ✔ tailor       0.1.0 \n✔ infer        1.0.9      ✔ tune         2.0.1 \n✔ modeldata    1.5.1      ✔ workflows    1.3.0 \n✔ parsnip      1.3.3      ✔ workflowsets 1.1.1 \n✔ purrr        1.2.0      ✔ yardstick    1.3.2 \n✔ recipes      1.3.1      \n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard()  masks scales::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\n# From https://www.tidymodels.org/start/recipes/#data-split\n\nset.seed(222)\n# Put 3/4 of the data into the training set \ndata_split &lt;- initial_split(df_daily, prop = 3/4, strata=seasons)\n\n# Create data frames for the two sets:\ntrain_data &lt;- training(data_split)\ntest_data  &lt;- testing(data_split)\n\n\n#check\ndim(test_data)\n\n[1] 92  9\n\ndim(train_data)\n\n[1] 273   9"
  },
  {
    "objectID": "hw8.html#next-generate-cv-folds",
    "href": "hw8.html#next-generate-cv-folds",
    "title": "Homework 8",
    "section": "",
    "text": "set.seed(222)\nfolds &lt;- vfold_cv(train_data, v = 10)"
  },
  {
    "objectID": "hw8.html#recipe-1",
    "href": "hw8.html#recipe-1",
    "title": "Homework 8",
    "section": "",
    "text": "colnames(train_data)\n\n[1] \"date\"             \"seasons\"          \"holiday\"          \"total_bikes\"     \n[5] \"total_rainfall\"   \"total_snowfall\"   \"mean_temperature\" \"mean_humidity\"   \n[9] \"mean_wind_speed\" \n\n\n\nbike_recipe &lt;- recipe(total_bikes ~ ., data = train_data) |&gt;\n  # extract date features\n  step_date(date, features = c(\"dow\")) |&gt;   # adds \"date_dow\" = day of week\n  \n  # create weekday/weekend variable\n  step_mutate(\n    day_type = factor(if_else(date_dow %in% c(\"Sat\", \"Sun\"), \"weekend\", \"weekday\"))\n  ) |&gt;\n  \n  # remove intermediate day-of-week variable\n  step_rm(date, date_dow) |&gt;\n  \n  # standardize (normalize) numeric variables\n  step_normalize(all_numeric_predictors()) |&gt;\n  \n  # create dummy variables for categorical predictors\n  step_dummy(all_nominal_predictors())"
  },
  {
    "objectID": "hw8.html#recipe-2",
    "href": "hw8.html#recipe-2",
    "title": "Homework 8",
    "section": "",
    "text": "bike_recipe2 &lt;- recipe(total_bikes ~ ., data = train_data) |&gt;\n  # extract date features\n  step_date(date, features = c(\"dow\")) |&gt;   # adds \"date_dow\" = day of week\n  \n  # create weekday/weekend variable\n  step_mutate(\n    day_type = factor(if_else(date_dow %in% c(\"Sat\", \"Sun\"), \"weekend\", \"weekday\"))\n  ) |&gt;\n  \n  # remove intermediate day-of-week variable\n  step_rm(date, date_dow) |&gt;\n  \n  # standardize (normalize) numeric variables\n  step_normalize(all_numeric_predictors()) |&gt;\n  \n  # create dummy variables for categorical predictors\n  step_dummy(all_nominal_predictors())|&gt;\n\n  # adding in the proper interactions\n  step_interact(~ starts_with(\"seasons\"):starts_with(\"holiday\"))|&gt;\n  step_interact(~starts_with(\"seasons\"):mean_temperature)|&gt;\n  step_interact(~total_rainfall:mean_temperature)"
  },
  {
    "objectID": "hw8.html#create-3rd-recipe",
    "href": "hw8.html#create-3rd-recipe",
    "title": "Homework 8",
    "section": "",
    "text": "bike_recipe3 &lt;- recipe(total_bikes ~ ., data = train_data) |&gt;\n  # extract date features\n  step_date(date, features = c(\"dow\")) |&gt;   # adds \"date_dow\" = day of week\n  \n  # create weekday/weekend variable\n  step_mutate(\n    day_type = factor(if_else(date_dow %in% c(\"Sat\", \"Sun\"), \"weekend\", \"weekday\"))\n  ) |&gt;\n  \n  # remove intermediate day-of-week variable\n  step_rm(date, date_dow) |&gt;\n  \n  # standardize (normalize) numeric variables\n  step_normalize(all_numeric_predictors()) |&gt;\n  \n  # create dummy variables for categorical predictors\n  step_dummy(all_nominal_predictors())|&gt;\n\n  # adding in the proper interactions\n  step_interact(~starts_with(\"seasons\"):starts_with(\"holiday\"))|&gt;\n  step_interact(~starts_with(\"seasons\"):mean_temperature)|&gt;\n  step_interact(~total_rainfall:mean_temperature)|&gt;\n\n  #create quadratic terms\n  step_poly(c(total_rainfall,total_snowfall,mean_temperature,mean_humidity,mean_wind_speed), degree = 2)"
  },
  {
    "objectID": "hw8.html#create-model",
    "href": "hw8.html#create-model",
    "title": "Homework 8",
    "section": "",
    "text": "lm_model &lt;- linear_reg() |&gt; \n  set_engine(\"lm\")"
  },
  {
    "objectID": "hw8.html#define-workflow-for-each-recipe",
    "href": "hw8.html#define-workflow-for-each-recipe",
    "title": "Homework 8",
    "section": "",
    "text": "bike_wf1 &lt;- workflow() |&gt;\n  add_model(lm_model) |&gt;\n  add_recipe(bike_recipe)\n\nbike_wf2 &lt;- workflow() |&gt;\n  add_model(lm_model) |&gt;\n  add_recipe(bike_recipe2)\n\nbike_wf3 &lt;- workflow() |&gt;\n  add_model(lm_model) |&gt;\n  add_recipe(bike_recipe3)"
  },
  {
    "objectID": "hw8.html#fit-the-models",
    "href": "hw8.html#fit-the-models",
    "title": "Homework 8",
    "section": "",
    "text": "bike_res1&lt;-fit_resamples(\n  bike_wf1,\n  resamples = folds,\n  metrics = metric_set(rmse, rsq),\n)\ncollect_metrics(bike_res1)\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config        \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard   6081.       10 491.     pre0_mod0_post0\n2 rsq     standard      0.649    10   0.0455 pre0_mod0_post0\n\n\n\n\n\n\nbike_res2&lt;-fit_resamples(\n  bike_wf2,\n  resamples = folds,\n  metrics = metric_set(rmse, rsq),\n)\n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x1\n\n\nThere were issues with some computations   A: x3\n\n\nThere were issues with some computations   A: x9\n\n\nThere were issues with some computations   A: x10\n\n\n\n\ncollect_metrics(bike_res2)\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config        \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard   5486.       10 467.     pre0_mod0_post0\n2 rsq     standard      0.706    10   0.0413 pre0_mod0_post0\n\n\n\n\n\n\nbike_res3&lt;-fit_resamples(\n  bike_wf3,\n  resamples = folds,\n  metrics = metric_set(rmse, rsq),\n)\n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x4\n\n\nThere were issues with some computations   A: x9\n\n\nThere were issues with some computations   A: x10\n\n\n\n\ncollect_metrics(bike_res3)\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config        \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard   5455.       10 477.     pre0_mod0_post0\n2 rsq     standard      0.711    10   0.0418 pre0_mod0_post0"
  },
  {
    "objectID": "hw8.html#final-model",
    "href": "hw8.html#final-model",
    "title": "Homework 8",
    "section": "",
    "text": "I will select the first model, it had the lowest RMSE.\n\n\n\nI will show the final model fit and the associated metrics.\n\n\nfinal_fit &lt;- last_fit(bike_wf1, split = data_split)\n\n\ncollect_metrics(final_fit)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config        \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard    6139.    pre0_mod0_post0\n2 rsq     standard       0.617 pre0_mod0_post0"
  },
  {
    "objectID": "hw8.html#get-the-final-coefficients",
    "href": "hw8.html#get-the-final-coefficients",
    "title": "Homework 8",
    "section": "",
    "text": "final_model &lt;- final_fit |&gt;\n  extract_fit_parsnip()\ntidy(final_model)\n\n# A tibble: 11 × 5\n   term               estimate std.error statistic  p.value\n   &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)        14715.       1913.    7.69   2.92e-13\n 2 total_rainfall     -2466.        459.   -5.38   1.68e- 7\n 3 total_snowfall         6.10      412.    0.0148 9.88e- 1\n 4 mean_temperature    5194.        887.    5.86   1.41e- 8\n 5 mean_humidity      -2271.        513.   -4.43   1.41e- 5\n 6 mean_wind_speed     -262.        405.   -0.647  5.18e- 1\n 7 seasons_Spring     -1570.       1092.   -1.44   1.52e- 1\n 8 seasons_Summer      2160.       1397.    1.55   1.23e- 1\n 9 seasons_Winter     -7774.       1650.   -4.71   3.99e- 6\n10 holiday_No.Holiday  4322.       1851.    2.33   2.03e- 2\n11 day_type_weekend   -1393.        831.   -1.68   9.48e- 2"
  }
]